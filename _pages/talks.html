---
layout: archive
title: "Talks and presentations"
permalink: /talks/
author_profile: true
---
<ul>
  <li> Talk at the NYU generative models foundations seminar. Oct. 2024. <i>Adjoint matching: fine-tuning flow and diffusion generative models with memoryless stochastic optimal control.</i> </li>
  <li> Talk & discussion at the Learning on Graphs & Geometry Reading Group. Sept. 2024. <i>Adjoint matching: fine-tuning flow and diffusion generative models with memoryless stochastic optimal control.</i> </li>
  <li> Talk at TransferLab Seminar. Sept. 2024. <i>Stochastic Optimal Control Matching.</i> </li>
  <li> Talk at Microsoft Research New England. March 2024. <i>Improving Generative Modeling and Stochastic Control by Matching Vector Fields.</i> </li>
  <li> Talk at Cornell Tech, Volodymyr Kuleshov's group. Feb. 2024. <i>Improving Generative Modeling and Stochastic Control by Matching Vector Fields.</i> </li>
  <li> Talk at Google Deepmind. Jan. 2024. <i>Stochastic Optimal Control Matching.</i> </li>
  <li> Talk at Flatiron Institute. Jan. 2024. <i>Improving Generative Modeling and Stochastic Control by Matching Vector Fields.</i> </li> 
  <li> Talk at Kempner Institute, Harvard University. Dec. 2023. <i>Improving Generative Modeling and Stochastic Control by Matching Vector Fields.</i> </li> 
  <li> Talk at Meta FAIR Labs. Nov. 2023. <i>Improving Generative Modeling and Stochastic Control by Matching Vector Fields.</i> </li>
  <li> Talk at Nvidia's Fundamental Generative AI group, Sept. 2023. <i>Speeding up generative modeling and distribution testing.</i> </li>
  <li> NYU Courant Seminar on Generative Modeling Foundations, Apr. 2023. <i>Multisample Flow Matching.</i> </li>
  <li> Microsoft Research New England Seminar, Feb. 2023. <i>Speeding up generative modeling and distribution testing.</i> </li>
  <li> Yingzhen Li's group meeting, Imperial College, July 2022. <i>Separation results between fixed-kernel and feature-learning probability metrics</i> & <i>Depth and Feature Learning are Provably Beneficial for Neural Network Discriminators.</i> </li>
  <li> Joan Bruna & Jason Lee's joint group meeting, June 2022. <i>Depth and Feature Learning are Provably Beneficial for Neural Network Discriminators.</i> </li>
  <li> IBM Research AI seminar, June 2022. <i>Auditing Differential Privacy in High Dimensions with the Kernel Quantum RÃ©nyi Divergence.</i> </li>
  <li> MIT - IBM Watson AI Lab invited seminar, March 2022. <i>Depth and Feature Learning are Provably Beneficial for Neural Network Discriminators.</i> </li>
  <li> MIT - IBM Watson AI Lab invited seminar, Nov. 2021. <i>Tighter sparse approximation bounds for ReLU neural networks.</i> </li>
  <li> MIT - IBM Watson AI Lab invited seminar, July 2021. <i>Separation results between fixed-kernel and feature-learning probability metrics.</i> </li>
  <li> Weinan E's group meeting at Princeton, April 2020. <i>A mean-field analysis of two-player zero-sum games.</i> </li>
  <li> Princeton PACM Graduate Student Seminar, March 2020. <i>A mean-field analysis of two-player zero-sum games.</i> </li>
</ul>
